{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ccc3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 – config & imports\n",
    "import gc, json, numpy as np, pandas as pd, os, hashlib\n",
    "\n",
    "FEATURE_PATH = \"../data/outputs/features.parquet\"\n",
    "TX_PATH = \"../data/input_data/transactions_train.csv\"\n",
    "FEATURE_COLS_JSON = \"../data/outputs/feature_cols.json\"\n",
    "\n",
    "LABEL_LOOKBACK_DAYS = 7\n",
    "NEG_SAMPLE_CLF = 1_000_000\n",
    "RANDOM_SEED = 42\n",
    "RANK_TOP_K_EVAL = 12\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def hex16_to_int(s):\n",
    "    return np.int64(np.uint64(int(s[-16:],16)))\n",
    "\n",
    "# Deterministic split function (modulus)\n",
    "def is_valid_customer(cid: int) -> bool:\n",
    "    return (cid % 5) == 0\n",
    "\n",
    "print(\"Config loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e4f317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (262416062, 28)\n",
      "Loaded columns: 28\n",
      "Number of feature_cols (including ids): 29\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 – load base features (already engineered) – memory safe\n",
    "# Load feature column order first (it already includes customer_id, article_id)\n",
    "if os.path.exists(FEATURE_COLS_JSON):\n",
    "    with open(FEATURE_COLS_JSON) as f:\n",
    "        feature_cols = json.load(f)[\"feature_cols\"]\n",
    "else:\n",
    "    # Fallback: read whole file once to derive columns\n",
    "    tmp_all = pd.read_parquet(FEATURE_PATH)\n",
    "    feature_cols = ['customer_id','article_id'] + [c for c in tmp_all.columns if c not in ['customer_id','article_id']]\n",
    "    del tmp_all\n",
    "    gc.collect()\n",
    "\n",
    "# Subset to only columns needed for modeling (exclude anything you no longer use)\n",
    "# Ensure id columns always present\n",
    "core_cols = ['customer_id','article_id']\n",
    "# Keep a minimal set of numeric / categorical predictors (adjust as needed)\n",
    "predictor_subset = [\n",
    "    'value','window_type_code',\n",
    "    'customer_total_purchases','customer_unique_articles',\n",
    "    'article_total_purchases','article_unique_customers',\n",
    "    'cust_purchases_1w','cust_purchases_4w',\n",
    "    'days_since_last_purchase','customer_days_since_last_purchase',\n",
    "    'age','club_member_status','fashion_news_frequency','postal_code',\n",
    "    'product_type_no','product_group_name','index_code','section_no',\n",
    "    'graphical_appearance_no','colour_group_code','perceived_colour_value_id',\n",
    "    'perceived_colour_master_id','index_group_no','garment_group_no',\n",
    "    'article_mean_price','customer_mean_price'\n",
    "]\n",
    "\n",
    "needed_cols = [c for c in feature_cols if c in (core_cols + predictor_subset)]\n",
    "# Read only required columns\n",
    "features = pd.read_parquet(FEATURE_PATH, columns=needed_cols)\n",
    "\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Loaded columns:\", len(needed_cols))\n",
    "\n",
    "# Types\n",
    "features['customer_id'] = features['customer_id'].astype('int64')\n",
    "features['article_id']  = features['article_id'].astype('int32')\n",
    "\n",
    "print(\"Number of feature_cols (including ids):\", len(feature_cols))\n",
    "\n",
    "# ~ 30gb of ram usage, 11s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f60e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive label rows: 213728\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 – build labels (last LABEL_LOOKBACK_DAYS) – optimized\n",
    "tx = pd.read_csv(\n",
    "    TX_PATH,\n",
    "    usecols=['t_dat','customer_id','article_id'],\n",
    "    dtype={'t_dat':'string','customer_id':'string','article_id':'int32'},\n",
    "    parse_dates=['t_dat']  # parse directly\n",
    ")\n",
    "tx['customer_id'] = tx['customer_id'].str[-16:].apply(hex16_to_int)\n",
    "\n",
    "last_ts = tx['t_dat'].max()\n",
    "cut_ts  = last_ts - pd.Timedelta(days=LABEL_LOOKBACK_DAYS)\n",
    "\n",
    "label_tx = tx[(tx['t_dat'] > cut_ts) & (tx['t_dat'] <= last_ts)][['customer_id','article_id']].drop_duplicates()\n",
    "labels = label_tx.assign(label=1)\n",
    "del label_tx, tx\n",
    "gc.collect()\n",
    "print(\"Positive label rows:\", len(labels))\n",
    "\n",
    "# ~ 24gb of ram usage, 3 min 47s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "544380a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset rows: 262416062 Pos covered: 47462 Total pos labels: 213728 Recall: 0.2221\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 – merge labels (unchanged logic, ensure categories preserved)\n",
    "data = features.merge(labels, on=['customer_id','article_id'], how='left')\n",
    "data['label'] = data['label'].fillna(0).astype('int8')\n",
    "\n",
    "# Compute coverage/recall before freeing labels\n",
    "total_pos_labels = int(len(labels))\n",
    "pos_covered = int(data['label'].sum())\n",
    "recall = (pos_covered / total_pos_labels) if total_pos_labels else 0.0\n",
    "\n",
    "del features, labels\n",
    "gc.collect()\n",
    "print(\n",
    "    \"Merged dataset rows:\", len(data),\n",
    "    \"Pos covered:\", pos_covered,\n",
    "    \"Total pos labels:\", total_pos_labels,\n",
    "    f\"Recall: {recall:.4f}\"\n",
    ")\n",
    "\n",
    "# ~ 34gb of ram usage, 1 min 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5676e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/outputs/model_base.parquet\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 – save full base dataset (for auditing / reuse)\n",
    "base_path = \"../data/outputs/model_base.parquet\"\n",
    "data.to_parquet(base_path, index=False)\n",
    "print(\"Saved:\", base_path)\n",
    "\n",
    "# ~ 18gb of ram usage, 1 min 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39bab8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique customers: 1371980\n",
      "Train rows (ranking): 210021247 Valid rows (ranking): 52394815\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 – deterministic split (vectorized, no apply)\n",
    "cust_ids = data['customer_id'].unique()\n",
    "print(\"Unique customers:\", len(cust_ids))\n",
    "\n",
    "valid_mask = (data['customer_id'] % 5) == 0\n",
    "train_mask = ~valid_mask\n",
    "\n",
    "# No .copy() unless you mutate\n",
    "train_full = data.loc[train_mask]\n",
    "valid_full = data.loc[valid_mask]\n",
    "\n",
    "print(\"Train rows (ranking):\", len(train_full), \"Valid rows (ranking):\", len(valid_full))\n",
    "\n",
    "# ~ 31gb of ram usage, 21s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b60541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ranking data + group arrays.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 – ranking groups (avoid sort if order not required for evaluation consistency)\n",
    "# If you need sorted customers for reproducibility keep the sort; otherwise skip to save time.\n",
    "train_full = train_full.sort_values('customer_id')\n",
    "valid_full = valid_full.sort_values('customer_id')\n",
    "\n",
    "train_group_sizes = train_full['customer_id'].value_counts(sort=False).sort_index().to_numpy()\n",
    "valid_group_sizes = valid_full['customer_id'].value_counts(sort=False).sort_index().to_numpy()\n",
    "\n",
    "np.save(\"../data/outputs/groups_train.npy\", train_group_sizes)\n",
    "np.save(\"../data/outputs/groups_valid.npy\", valid_group_sizes)\n",
    "\n",
    "train_full.to_parquet(\"../data/outputs/train_rank.parquet\", index=False)\n",
    "valid_full.to_parquet(\"../data/outputs/valid_rank.parquet\", index=False)\n",
    "print(\"Saved ranking data + group arrays.\")\n",
    "\n",
    "# ~ 45gb of ram usage, 3 min 2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a827e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier train rows: 1037970 pos: 37970\n",
      "Classifier valid rows: 52394815 pos: 9492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8 – classifier negative sampling (slightly leaner)\n",
    "y_train_full = train_full['label'].to_numpy()\n",
    "pos_train_idx = np.where(y_train_full == 1)[0]\n",
    "neg_train_idx = np.where(y_train_full == 0)[0]\n",
    "\n",
    "if len(neg_train_idx) > NEG_SAMPLE_CLF:\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "    neg_train_idx = rng.choice(neg_train_idx, size=NEG_SAMPLE_CLF, replace=False)\n",
    "\n",
    "clf_train_idx = np.concatenate([pos_train_idx, neg_train_idx])\n",
    "clf_train = train_full.iloc[clf_train_idx]\n",
    "clf_valid = valid_full  # keep all\n",
    "\n",
    "model_features_local = [c for c in feature_cols if c in clf_train.columns and c not in ['customer_id','article_id','label']]\n",
    "keep_cols = ['customer_id','article_id','label'] + model_features_local\n",
    "clf_train = clf_train.loc[:, keep_cols]\n",
    "clf_valid = clf_valid.loc[:, keep_cols]\n",
    "\n",
    "clf_train.to_parquet(\"../data/outputs/train_clf.parquet\", index=False)\n",
    "clf_valid.to_parquet(\"../data/outputs/valid_clf.parquet\", index=False)\n",
    "\n",
    "print(\"Classifier train rows:\", len(clf_train), \"pos:\", (clf_train.label==1).sum())\n",
    "print(\"Classifier valid rows:\", len(clf_valid), \"pos:\", (clf_valid.label==1).sum())\n",
    "del y_train_full, pos_train_idx, neg_train_idx, clf_train_idx\n",
    "gc.collect()\n",
    "\n",
    "# ~ 45gb of ram usage, 3 min 2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a672c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta saved.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 – meta (add memory info)\n",
    "model_features = [c for c in feature_cols if c not in ['customer_id','article_id','label'] and c in data.columns]\n",
    "\n",
    "with open(\"../data/outputs/dataset_meta.json\",\"w\") as f:\n",
    "    json.dump({\n",
    "        \"last_ts\": str(last_ts),\n",
    "        \"cut_ts\": str(cut_ts),\n",
    "        \"label_lookback_days\": LABEL_LOOKBACK_DAYS,\n",
    "        \"neg_sample_clf\": NEG_SAMPLE_CLF,\n",
    "        \"feature_cols_full\": feature_cols,\n",
    "        \"model_features\": model_features,\n",
    "        \"rank_train_rows\": len(train_full),\n",
    "        \"rank_valid_rows\": len(valid_full),\n",
    "        \"clf_train_rows\": len(clf_train),\n",
    "        \"clf_valid_rows\": len(clf_valid),\n",
    "        \"rank_at\": RANK_TOP_K_EVAL\n",
    "    }, f)\n",
    "\n",
    "print(\"Meta saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44786e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup done.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 – cleanup\n",
    "del data, train_full, valid_full, clf_train, clf_valid\n",
    "gc.collect()\n",
    "print(\"Cleanup done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e604b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
