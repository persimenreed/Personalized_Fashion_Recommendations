{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "852fcb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import gc\n",
    "\n",
    "import cudf\n",
    "\n",
    "import os\n",
    "os.environ['HM_TARGET_WEEK_END'] = '2020-08-19'\n",
    "TARGET_WEEK_END = os.environ.get(\"HM_TARGET_WEEK_END\")\n",
    "printdate = TARGET_WEEK_END\n",
    "assert TARGET_WEEK_END is not None, \"Set HM_TARGET_WEEK_END=YYYY-MM-DD\"\n",
    "TARGET_WEEK_END = pd.to_datetime(TARGET_WEEK_END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5f31722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "\n",
    "N = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32c01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "\n",
    "df = cudf.read_csv(\n",
    "    '../data/input_data/transactions_train.csv',\n",
    "    usecols=['t_dat', 'customer_id', 'article_id'],\n",
    "    dtype={'t_dat': 'string', 'customer_id': 'string', 'article_id': 'int32'},\n",
    ")\n",
    "\n",
    "# Map customer_id to int64 (same as other pipelines)\n",
    "df['customer_id'] = df['customer_id'].str[-16:].str.hex_to_int().astype('int64')\n",
    "\n",
    "df['t_dat'] = cudf.to_datetime(df['t_dat'])\n",
    "last_ts = TARGET_WEEK_END\n",
    "\n",
    "# define cutoff for training history (exclude last 7 days)\n",
    "cut_ts = last_ts - pd.Timedelta(days=7)\n",
    "\n",
    "# Filter to history only (everything up to and including cut_ts)\n",
    "df = df[df['t_dat'] <= cut_ts]\n",
    "\n",
    "# Week / biweek / month cutoffs based on cut_ts (not last_ts)\n",
    "week_start   = cut_ts - pd.Timedelta(days=7)\n",
    "biweek_start = cut_ts - pd.Timedelta(days=14)\n",
    "month_start  = cut_ts - pd.Timedelta(days=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3e14e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4753/1325120669.py:6: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  tmp['ldbw'] = tmp['t_dat'] - pd.TimedeltaIndex(tmp['dow'] - 1, unit='D')\n",
      "/tmp/ipykernel_4753/1325120669.py:9: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  + pd.TimedeltaIndex(np.ones(len(tmp.loc[tmp['dow'] >= 2])) * 7, unit='D')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4\n",
    "\n",
    "# Compute \"last date of the week\" bucket (ldbw) on CPU using pandas\n",
    "tmp = df[['t_dat']].copy().to_pandas()\n",
    "tmp['dow'] = tmp['t_dat'].dt.dayofweek\n",
    "tmp['ldbw'] = tmp['t_dat'] - pd.TimedeltaIndex(tmp['dow'] - 1, unit='D')\n",
    "tmp.loc[tmp['dow'] >= 2, 'ldbw'] = (\n",
    "    tmp.loc[tmp['dow'] >= 2, 'ldbw']\n",
    "    + pd.TimedeltaIndex(np.ones(len(tmp.loc[tmp['dow'] >= 2])) * 7, unit='D')\n",
    ")\n",
    "\n",
    "df['ldbw'] = tmp['ldbw'].values\n",
    "del tmp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "144a8734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5\n",
    "\n",
    "# Weekly sales count per (ldbw, article_id)\n",
    "weekly_sales = df.drop('customer_id', axis=1).groupby(['ldbw', 'article_id']).count().reset_index()\n",
    "weekly_sales = weekly_sales.rename(columns={'t_dat': 'count'})\n",
    "\n",
    "# Merge weekly count into df\n",
    "df = df.merge(weekly_sales, on=['ldbw', 'article_id'], how='left')\n",
    "\n",
    "# FIX: Calculate target_ldbw to match the logic used for the dataframe\n",
    "# The ldbw logic aligns dates to the following Tuesday.\n",
    "# We must apply the same transformation to cut_ts to find the correct bucket.\n",
    "cut_dow = cut_ts.dayofweek\n",
    "target_ldbw = cut_ts - pd.Timedelta(days=cut_dow - 1)\n",
    "if cut_dow >= 2:\n",
    "    target_ldbw = target_ldbw + pd.Timedelta(days=7)\n",
    "\n",
    "# For each article, get count in the last week (target week = week ending at cut_ts)\n",
    "weekly_sales = weekly_sales.reset_index().set_index('article_id')\n",
    "df = df.merge(\n",
    "    weekly_sales.loc[weekly_sales['ldbw'] == target_ldbw, ['count']],\n",
    "    on='article_id',\n",
    "    suffixes=('', '_targ')\n",
    ")\n",
    "\n",
    "df['count_targ'].fillna(0, inplace=True)\n",
    "del weekly_sales\n",
    "gc.collect()\n",
    "\n",
    "# Quotient = \"importance\" of this article in this week vs target week\n",
    "df['quotient'] = df['count_targ'] / df['count']\n",
    "\n",
    "# target_sales: sum of quotient per article over all weeks\n",
    "target_sales = df.drop('customer_id', axis=1).groupby('article_id')['quotient'].sum()\n",
    "\n",
    "# Global top-N articles\n",
    "general_pred = target_sales.nlargest(N).index.to_pandas().tolist()\n",
    "general_pred = ['0' + str(article_id) for article_id in general_pred]\n",
    "general_pred_str = ' '.join(general_pred)\n",
    "\n",
    "# Save so the ranker / submission notebook can reuse the same global list\n",
    "pd.Series({'general_pred_str': general_pred_str}).to_json(\n",
    "    '../data/outputs/general_pred_str.json'\n",
    ")\n",
    "\n",
    "del target_sales\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "590d51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "\n",
    "# Move to pandas for easier numeric ops\n",
    "tmp = df.copy().to_pandas()\n",
    "\n",
    "# Days since transaction\n",
    "tmp['x'] = ((last_ts - tmp['t_dat']) / np.timedelta64(1, 'D')).astype(int)\n",
    "tmp['dummy_1'] = 1\n",
    "tmp['x'] = tmp[['x', 'dummy_1']].max(axis=1)\n",
    "\n",
    "# Recency weighting function\n",
    "a, b, c, d = 2.5e4, 1.5e5, 2e-1, 1e3\n",
    "tmp['y'] = a / np.sqrt(tmp['x']) + b * np.exp(-c * tmp['x']) - d\n",
    "\n",
    "tmp['dummy_0'] = 0\n",
    "tmp['y'] = tmp[['y', 'dummy_0']].max(axis=1)\n",
    "\n",
    "# Final value per transaction\n",
    "tmp['value'] = tmp['quotient'] * tmp['y']\n",
    "\n",
    "# Aggregate per (customer_id, article_id)\n",
    "tmp = tmp.groupby(['customer_id', 'article_id']).agg({'value': 'sum'}).reset_index()\n",
    "\n",
    "# Keep reasonably candidates\n",
    "tmp = tmp.loc[tmp['value'] > 20]\n",
    "\n",
    "# Rank per customer and keep top-N\n",
    "tmp['rank'] = tmp.groupby('customer_id')['value'].rank('dense', ascending=False)\n",
    "tmp = tmp.loc[tmp['rank'] <= N]\n",
    "\n",
    "# Sorted candidate list\n",
    "purchase_df = tmp.sort_values(['customer_id', 'value'], ascending=False).reset_index(drop=True)\n",
    "purchase_df = cudf.DataFrame(purchase_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "161753b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "\n",
    "# Base candidates (customer_id, article_id, value)\n",
    "candidates = purchase_df[['customer_id', 'article_id', 'value']].copy()\n",
    "candidates = candidates.sort_values(['customer_id', 'value'], ascending=False)\n",
    "\n",
    "# Build recency window_type using last purchase timestamp per (customer, article)\n",
    "df_min = df[['customer_id', 'article_id', 't_dat']].to_pandas()\n",
    "df_min = df_min.sort_values('t_dat').drop_duplicates(['customer_id', 'article_id'], keep='last')\n",
    "\n",
    "candidates = candidates.to_pandas()\n",
    "candidates = candidates.merge(df_min, on=['customer_id', 'article_id'], how='left')\n",
    "\n",
    "# Classify into window_type: weekly / biweekly / monthly / older\n",
    "candidates['window_type'] = 'older'\n",
    "candidates.loc[candidates['t_dat'] >= week_start, 'window_type'] = 'weekly'\n",
    "candidates.loc[\n",
    "    (candidates['t_dat'] < week_start)\n",
    "    & (candidates['t_dat'] >= biweek_start),\n",
    "    'window_type'\n",
    "] = 'biweekly'\n",
    "candidates.loc[\n",
    "    (candidates['t_dat'] < biweek_start)\n",
    "    & (candidates['t_dat'] >= month_start),\n",
    "    'window_type'\n",
    "] = 'monthly'\n",
    "\n",
    "# Keep only the needed columns\n",
    "candidates = candidates[['customer_id', 'article_id', 'value', 'window_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d8f68ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>value</th>\n",
       "      <th>window_type</th>\n",
       "      <th>customer_id_hex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9221253129171208814</td>\n",
       "      <td>839194001</td>\n",
       "      <td>171.302673</td>\n",
       "      <td>older</td>\n",
       "      <td>cd1de704ae85eb8aeee2afa8411a73d7f42279b844e3d6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9221253129171208814</td>\n",
       "      <td>859205001</td>\n",
       "      <td>55.258930</td>\n",
       "      <td>older</td>\n",
       "      <td>cd1de704ae85eb8aeee2afa8411a73d7f42279b844e3d6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9221240110313799789</td>\n",
       "      <td>816423004</td>\n",
       "      <td>1589.881470</td>\n",
       "      <td>monthly</td>\n",
       "      <td>0bb4126978be1d2abdfe83fa1833055eebd0a918423139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9221240110313799789</td>\n",
       "      <td>779725006</td>\n",
       "      <td>329.196594</td>\n",
       "      <td>older</td>\n",
       "      <td>0bb4126978be1d2abdfe83fa1833055eebd0a918423139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9221240110313799789</td>\n",
       "      <td>811907004</td>\n",
       "      <td>310.284637</td>\n",
       "      <td>older</td>\n",
       "      <td>0bb4126978be1d2abdfe83fa1833055eebd0a918423139...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           customer_id  article_id        value window_type  \\\n",
       "0  9221253129171208814   839194001   171.302673       older   \n",
       "1  9221253129171208814   859205001    55.258930       older   \n",
       "2  9221240110313799789   816423004  1589.881470     monthly   \n",
       "3  9221240110313799789   779725006   329.196594       older   \n",
       "4  9221240110313799789   811907004   310.284637       older   \n",
       "\n",
       "                                     customer_id_hex  \n",
       "0  cd1de704ae85eb8aeee2afa8411a73d7f42279b844e3d6...  \n",
       "1  cd1de704ae85eb8aeee2afa8411a73d7f42279b844e3d6...  \n",
       "2  0bb4126978be1d2abdfe83fa1833055eebd0a918423139...  \n",
       "3  0bb4126978be1d2abdfe83fa1833055eebd0a918423139...  \n",
       "4  0bb4126978be1d2abdfe83fa1833055eebd0a918423139...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8\n",
    "\n",
    "import cudf\n",
    "\n",
    "candidates = cudf.DataFrame(candidates)\n",
    "\n",
    "# Map int customer_id back to hex string form for consistency with sample_submission\n",
    "customers = cudf.read_csv(\n",
    "    '../data/input_data/sample_submission.csv',\n",
    "    usecols=['customer_id'],\n",
    "    dtype={'customer_id': 'string'}\n",
    ")\n",
    "customers['customer_id_int'] = customers['customer_id'].str[-16:].str.hex_to_int().astype('int64')\n",
    "\n",
    "# Merge so that we keep the int id as 'customer_id' and add hex as 'customer_id_hex'\n",
    "candidates = candidates.merge(\n",
    "    customers[['customer_id', 'customer_id_int']],\n",
    "    left_on='customer_id',\n",
    "    right_on='customer_id_int',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "candidates = candidates.rename(\n",
    "    columns={'customer_id_x': 'customer_id', 'customer_id_y': 'customer_id_hex'}\n",
    ")\n",
    "candidates = candidates.drop('customer_id_int', axis=1)\n",
    "\n",
    "del customers\n",
    "gc.collect()\n",
    "\n",
    "# Ensure dtypes are as expected for downstream processing\n",
    "candidates['article_id'] = candidates['article_id'].astype('int32')\n",
    "candidates['value']      = candidates['value'].astype('float32')\n",
    "\n",
    "# Deduplicate just in case\n",
    "candidates = candidates.drop_duplicates(['customer_id', 'article_id'])\n",
    "\n",
    "candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d018fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9\n",
    "\n",
    "#candidates.to_pandas().to_csv('../data/outputs/candidates_weekly_trending.csv', index=False)\n",
    "candidates.to_pandas().to_parquet(f'../data/outputs/candidates/candidates_weekly_trending_{printdate}.parquet', index=False)\n",
    "\n",
    "del df, df_min, purchase_df, candidates\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094672c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9b53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d1ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
