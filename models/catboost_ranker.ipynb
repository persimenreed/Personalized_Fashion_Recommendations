{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11391d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Cell 1 – imports\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRanker, Pool\n",
    "\n",
    "META_PATH = '../data/outputs/dataset_meta.json'\n",
    "TRAIN_RANK_PATH = '../data/outputs/train_rank.parquet'\n",
    "VALID_RANK_PATH = '../data/outputs/valid_rank.parquet'\n",
    "GROUP_VALID_PATH = '../data/outputs/groups_valid.npy'\n",
    "FEATURES_PATH = '../data/outputs/features_week=20200922.parquet'\n",
    "SAMPLE_PATH = '../data/input_data/sample_submission.csv'\n",
    "GENERAL_PATH = '../data/outputs/general_pred_str.json'\n",
    "MODEL_PATH = '../data/outputs/catboost_ranker.model'\n",
    "SUB_PATH = '../data/submission/catboost_ranker_submission.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8971e143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 8180082\n",
      "Valid rows: 253714158\n",
      "Features: 34\n",
      "Groups train: 294983 valid: 1371980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 2 – load train/valid ranking data\n",
    "META_PATH = '../data/outputs/dataset_meta.json'\n",
    "TRAIN_RANK_PATH = '../data/outputs/train_rank.parquet'\n",
    "VALID_RANK_PATH = '../data/outputs/valid_rank.parquet'\n",
    "GROUP_TRAIN_PATH = '../data/outputs/groups_train.npy'\n",
    "GROUP_VALID_PATH = '../data/outputs/groups_valid.npy'\n",
    "\n",
    "with open(META_PATH) as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "# same feature list used in LGBM/XGB\n",
    "feature_cols = meta['model_features']\n",
    "\n",
    "# load\n",
    "train_df = pd.read_parquet(TRAIN_RANK_PATH)\n",
    "valid_df = pd.read_parquet(VALID_RANK_PATH)\n",
    "\n",
    "# REMOVE FEATURES – same list as XGB/LGBM\n",
    "remove_features = [\n",
    "    # same list you used in the others\n",
    "]\n",
    "\n",
    "# drop removed features\n",
    "drop_cols = [c for c in remove_features if c in train_df.columns]\n",
    "if drop_cols:\n",
    "    print(\"Dropping:\", drop_cols)\n",
    "    train_df = train_df.drop(columns=drop_cols)\n",
    "    valid_df = valid_df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# update feature_cols\n",
    "feature_cols = [c for c in feature_cols if c not in remove_features]\n",
    "\n",
    "train_group = np.load(GROUP_TRAIN_PATH)\n",
    "valid_group = np.load(GROUP_VALID_PATH)\n",
    "\n",
    "# float32 for GPU CatBoost\n",
    "for c in feature_cols:\n",
    "    if pd.api.types.is_float_dtype(train_df[c]):\n",
    "        train_df[c] = train_df[c].astype('float32')\n",
    "        valid_df[c] = valid_df[c].astype('float32')\n",
    "\n",
    "train_df['label'] = train_df['label'].astype('float32')\n",
    "valid_df['label'] = valid_df['label'].astype('float32')\n",
    "\n",
    "print(\"Train rows:\", len(train_df))\n",
    "print(\"Valid rows:\", len(valid_df))\n",
    "print(\"Features:\", len(feature_cols))\n",
    "print(\"Groups train:\", len(train_group), \"valid:\", len(valid_group))\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1ce40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering validation set to groups with at least 1 positive...\n",
      "Filtered valid groups: 27802\n",
      "Filtered valid rows: 8372080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 3 – filter validation groups with ≥1 positive\n",
    "\n",
    "print(\"\\nFiltering validation set to groups with at least 1 positive...\")\n",
    "\n",
    "orig_valid_group = np.load(GROUP_VALID_PATH)\n",
    "group_bounds = np.insert(np.cumsum(orig_valid_group), 0, 0)[:-1]\n",
    "group_has_positive = np.add.reduceat(valid_df['label'].values, group_bounds) > 0\n",
    "\n",
    "valid_group = orig_valid_group[group_has_positive]\n",
    "row_mask = np.repeat(group_has_positive, orig_valid_group)\n",
    "valid_df = valid_df[row_mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Filtered valid groups:\", len(valid_group))\n",
    "print(\"Filtered valid rows:\", len(valid_df))\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88aaad49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded train_group_id: 8180082\n",
      "Expanded valid_group_id: 8372080\n",
      "Train_df rows: 8180082\n",
      "Valid_df rows: 8372080\n",
      "Pools built:\n",
      "Train rows: 8180082\n",
      "Valid rows: 8372080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 4 – Build CatBoost Pools (aligned with LGBM/XGB)\n",
    "\n",
    "from catboost import Pool\n",
    "\n",
    "# --- Convert group-sizes to per-row group_id (CatBoost requirement) ---\n",
    "def expand_group_ids(group_sizes):\n",
    "    ids = np.repeat(np.arange(len(group_sizes), dtype=np.int32), group_sizes)\n",
    "    return ids\n",
    "\n",
    "train_group_id = expand_group_ids(train_group)\n",
    "valid_group_id = expand_group_ids(valid_group)\n",
    "\n",
    "print(\"Expanded train_group_id:\", len(train_group_id))\n",
    "print(\"Expanded valid_group_id:\", len(valid_group_id))\n",
    "print(\"Train_df rows:\", len(train_df))\n",
    "print(\"Valid_df rows:\", len(valid_df))\n",
    "\n",
    "assert len(train_group_id) == len(train_df)\n",
    "assert len(valid_group_id) == len(valid_df)\n",
    "\n",
    "# Treat all features as numeric\n",
    "cat_features = []\n",
    "\n",
    "pool_train = Pool(\n",
    "    data=train_df[feature_cols],\n",
    "    label=train_df[\"label\"],\n",
    "    group_id=train_group_id,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "pool_valid = Pool(\n",
    "    data=valid_df[feature_cols],\n",
    "    label=valid_df[\"label\"],\n",
    "    group_id=valid_group_id,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "print(\"Pools built:\")\n",
    "print(\"Train rows:\", pool_train.shape[0])\n",
    "print(\"Valid rows:\", pool_valid.shape[0])\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bd5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric PFound is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric NDCG:top=12;type=Base is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.1065279\tbest: 0.1065279 (0)\ttotal: 329ms\tremaining: 32.5s\n",
      "10:\ttest: 0.1156121\tbest: 0.1156121 (10)\ttotal: 1.85s\tremaining: 15s\n",
      "20:\ttest: 0.1331676\tbest: 0.1331676 (20)\ttotal: 3.4s\tremaining: 12.8s\n",
      "30:\ttest: 0.1356985\tbest: 0.1356985 (30)\ttotal: 4.93s\tremaining: 11s\n",
      "40:\ttest: 0.1405683\tbest: 0.1405718 (39)\ttotal: 6.46s\tremaining: 9.3s\n",
      "50:\ttest: 0.1426873\tbest: 0.1426873 (50)\ttotal: 8.07s\tremaining: 7.76s\n",
      "60:\ttest: 0.1439404\tbest: 0.1440354 (59)\ttotal: 9.64s\tremaining: 6.17s\n",
      "70:\ttest: 0.1446463\tbest: 0.1447158 (66)\ttotal: 11.2s\tremaining: 4.58s\n",
      "80:\ttest: 0.1466995\tbest: 0.1466995 (80)\ttotal: 12.8s\tremaining: 3s\n",
      "90:\ttest: 0.1472478\tbest: 0.1472478 (90)\ttotal: 14.4s\tremaining: 1.42s\n",
      "99:\ttest: 0.1472252\tbest: 0.1474337 (97)\ttotal: 15.8s\tremaining: 0us\n",
      "bestTest = 0.1474337369\n",
      "bestIteration = 97\n",
      "Shrink model to first 98 iterations.\n",
      "Best iteration: 97\n",
      "Model saved: ../data/outputs/catboost_ranker.model\n",
      "Available eval keys:\n",
      "Learn keys: []\n",
      "Validation keys: ['PFound', 'NDCG:top=12;type=Base']\n",
      "Using validation metric: NDCG:top=12;type=Base\n",
      "Training log saved successfully: ../data/outputs/catboost_training_log.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 5 – GPU CatBoostRanker with eval logging\n",
    "\n",
    "MODEL_PATH = \"../data/outputs/catboost_ranker.model\"\n",
    "LOG_PATH = \"../data/outputs/catboost_training_log.txt\"\n",
    "\n",
    "model = CatBoostRanker(\n",
    "    loss_function='YetiRank',\n",
    "    eval_metric='NDCG:top=12',\n",
    "    learning_rate=0.08,\n",
    "    depth=10,\n",
    "    l2_leaf_reg=15,\n",
    "    min_data_in_leaf=256,\n",
    "    border_count=128, \n",
    "    iterations=100,\n",
    "    early_stopping_rounds=100,\n",
    "    task_type='GPU',\n",
    "    devices='0',\n",
    "    random_seed=42,\n",
    "    verbose=10,\n",
    "    metric_period=10,\n",
    ")\n",
    "\n",
    "model.fit(pool_train, eval_set=pool_valid)\n",
    "\n",
    "\n",
    "# model = CatBoostRanker(\n",
    "#     loss_function='YetiRank',\n",
    "#     eval_metric='NDCG:top=12',\n",
    "#     learning_rate=0.05,\n",
    "#     depth=6,\n",
    "#     iterations=500,\n",
    "#     border_count=64,\n",
    "#     random_seed=42,\n",
    "#     early_stopping_rounds=50,\n",
    "#     task_type='GPU',\n",
    "#     devices='0',\n",
    "#     gpu_ram_part=0.7,\n",
    "#     one_hot_max_size=10,\n",
    "#     max_ctr_complexity=1,\n",
    "#     verbose=10,\n",
    "#     metric_period=10,\n",
    "# )\n",
    "# model.fit(pool_train, eval_set=pool_valid)\n",
    "\n",
    "print(\"Best iteration:\", model.get_best_iteration())\n",
    "\n",
    "# Save model\n",
    "model.save_model(MODEL_PATH)\n",
    "print(\"Model saved:\", MODEL_PATH)\n",
    "\n",
    "# ---- LOGGING ----\n",
    "evals = model.get_evals_result()\n",
    "\n",
    "# Find the key containing NDCG in validation set\n",
    "def find_ndcg_key(eval_dict):\n",
    "    for key in eval_dict:\n",
    "        if \"NDCG\" in key.upper():\n",
    "            return key\n",
    "    # If not found, return first available key or raise error\n",
    "    available = list(eval_dict.keys())\n",
    "    if available:\n",
    "        print(f\"Warning: NDCG not found. Using first available metric: {available[0]}\")\n",
    "        return available[0]\n",
    "    raise KeyError(f\"No metrics found in eval_dict. Available keys: {available}\")\n",
    "\n",
    "valid_metric_key = find_ndcg_key(evals['validation'])\n",
    "print(f\"Using validation metric: {valid_metric_key}\")\n",
    "\n",
    "# Since learn is empty, we'll only log validation metrics\n",
    "valid_log = evals['validation'][valid_metric_key]\n",
    "\n",
    "with open(LOG_PATH, \"w\") as f:\n",
    "    f.write(\"iter,valid_ndcg12\\n\")\n",
    "    for i, val in enumerate(valid_log):\n",
    "        f.write(f\"{i},{val}\\n\")\n",
    "\n",
    "print(\"Training log saved successfully:\", LOG_PATH)\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ba382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 6 – cleanup after training\n",
    "del pool_train, pool_valid\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f10041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model for inference...\n",
      "Loading submission week features...\n",
      "Running inference...\n",
      "Scored data rows: 250982495\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 7 – inference on submission week\n",
    "\n",
    "print(\"\\nLoading model for inference...\")\n",
    "model = CatBoostRanker()\n",
    "model.load_model(MODEL_PATH)\n",
    "\n",
    "print(\"Loading submission week features...\")\n",
    "data = pd.read_parquet(\n",
    "    FEATURES_PATH,\n",
    "    columns=[\"customer_id\", \"article_id\"] + feature_cols\n",
    ")\n",
    "\n",
    "data[\"customer_id\"] = data[\"customer_id\"].astype(\"int64\")\n",
    "data[\"article_id\"] = data[\"article_id\"].astype(\"int32\")\n",
    "\n",
    "for c in feature_cols:\n",
    "    if pd.api.types.is_float_dtype(data[c]):\n",
    "        data[c] = data[c].astype(\"float32\")\n",
    "\n",
    "infer_pool = Pool(\n",
    "    data=data[feature_cols],\n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "print(\"Running inference...\")\n",
    "scores = model.predict(infer_pool).astype(np.float32)\n",
    "data[\"score\"] = scores\n",
    "\n",
    "del infer_pool, scores\n",
    "gc.collect()\n",
    "print(\"Scored data rows:\", len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9503d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49306/3103779477.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top12[\"article_id_str\"] = top12[\"article_id\"].astype(str).str.zfill(10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions built: 1371980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 8 – top-12 per customer\n",
    "\n",
    "data = data.sort_values([\"customer_id\", \"score\"], ascending=[True, False])\n",
    "top12 = data.groupby(\"customer_id\", group_keys=False).head(12)\n",
    "\n",
    "top12[\"article_id_str\"] = top12[\"article_id\"].astype(str).str.zfill(10)\n",
    "\n",
    "pred_df = (\n",
    "    top12.groupby(\"customer_id\")[\"article_id_str\"]\n",
    "         .apply(lambda x: \" \".join(x))\n",
    "         .reset_index()\n",
    "         .rename(columns={\"customer_id\": \"customer_id_int\",\n",
    "                          \"article_id_str\": \"prediction\"})\n",
    ")\n",
    "\n",
    "pred_df[\"customer_id_int\"] = pred_df[\"customer_id_int\"].astype(\"int64\")\n",
    "\n",
    "print(\"Predictions built:\", len(pred_df))\n",
    "\n",
    "del top12, data\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b4a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample customers: 1371980\n",
      "Predicted customers: 1371980\n",
      "Predictions matched: 1371980\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 9 – merge with sample + fallback\n",
    "\n",
    "def hex16_to_int(s):\n",
    "    return np.int64(np.uint64(int(s[-16:], 16)))\n",
    "\n",
    "sample = pd.read_csv(SAMPLE_PATH)\n",
    "sample[\"customer_id_int\"] = sample[\"customer_id\"].apply(hex16_to_int)\n",
    "sample = sample.drop(columns=[\"prediction\"], errors=\"ignore\")\n",
    "\n",
    "pred_df[\"customer_id_int\"] = pred_df[\"customer_id_int\"].astype(\"int64\")\n",
    "\n",
    "print(\"Sample customers:\", sample[\"customer_id_int\"].nunique())\n",
    "print(\"Predicted customers:\", pred_df[\"customer_id_int\"].nunique())\n",
    "\n",
    "sub = sample.merge(pred_df, how=\"left\", on=\"customer_id_int\")\n",
    "print(\"Predictions matched:\", sub[\"prediction\"].notna().sum())\n",
    "\n",
    "del sample, pred_df\n",
    "gc.collect()\n",
    "\n",
    "gp = json.load(open(GENERAL_PATH))\n",
    "fallback_str = gp[\"general_pred_str\"]\n",
    "fallback_items = fallback_str.split()\n",
    "\n",
    "sub[\"prediction\"] = sub[\"prediction\"].fillna(fallback_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992884f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: ../data/submission/catboost_ranker_submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_id_int</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>6883939031699146327</td>\n",
       "      <td>0568601006 0568601043 0568601044 0568601007 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>-7200416642310594310</td>\n",
       "      <td>0673677002 0918522001 0924243001 0918292001 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>-6846340800584936</td>\n",
       "      <td>0794321007 0794321011 0794321008 0918522001 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>-94071612138601410</td>\n",
       "      <td>0804992017 0794321011 0805000001 0754238024 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>-283965518499174310</td>\n",
       "      <td>0896152002 0791587015 0730683050 0730683062 08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id      customer_id_int  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...  6883939031699146327   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e... -7200416642310594310   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...    -6846340800584936   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   -94071612138601410   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...  -283965518499174310   \n",
       "\n",
       "                                          prediction  \n",
       "0  0568601006 0568601043 0568601044 0568601007 09...  \n",
       "1  0673677002 0918522001 0924243001 0918292001 09...  \n",
       "2  0794321007 0794321011 0794321008 0918522001 08...  \n",
       "3  0804992017 0794321011 0805000001 0754238024 07...  \n",
       "4  0896152002 0791587015 0730683050 0730683062 08...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 10 – pad to 12 and save\n",
    "\n",
    "def pad_to_12(pred):\n",
    "    items = pred.split()\n",
    "    if len(items) >= 12:\n",
    "        return \" \".join(items[:12])\n",
    "    seen = set(items)\n",
    "    for art in fallback_items:\n",
    "        if art not in seen:\n",
    "            items.append(art)\n",
    "            seen.add(art)\n",
    "        if len(items) == 12:\n",
    "            break\n",
    "    return \" \".join(items)\n",
    "\n",
    "sub[\"prediction\"] = sub[\"prediction\"].apply(pad_to_12)\n",
    "\n",
    "sub[[\"customer_id\", \"prediction\"]].to_csv(SUB_PATH, index=False)\n",
    "print(\"Submission saved to:\", SUB_PATH)\n",
    "\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e54fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
