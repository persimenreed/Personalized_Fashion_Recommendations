{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11391d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 – imports\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRanker, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8971e143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 128475160 Valid rows: 32048094\n",
      "Features used: 26\n",
      "Categorical feature count: 14\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 – load prepared ranking data\n",
    "META_PATH = '../data/outputs/dataset_meta.json'\n",
    "TRAIN_RANK_PATH = '../data/outputs/train_rank.parquet'\n",
    "VALID_RANK_PATH = '../data/outputs/valid_rank.parquet'\n",
    "\n",
    "with open(META_PATH) as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "feature_cols = meta['model_features']  # same intersected list\n",
    "\n",
    "train_df = pd.read_parquet(TRAIN_RANK_PATH)\n",
    "valid_df = pd.read_parquet(VALID_RANK_PATH)\n",
    "\n",
    "# Enforce intersection (safety) and drop non-feature cols\n",
    "available = set(train_df.columns)\n",
    "feature_cols = [c for c in feature_cols\n",
    "                if c in available and c not in ['customer_id', 'label', 'group_idx']]\n",
    "\n",
    "# OPTIONAL but recommended: drop unused columns early to save RAM\n",
    "keep_cols = feature_cols + ['customer_id', 'label']\n",
    "train_df = train_df[keep_cols]\n",
    "valid_df = valid_df[keep_cols]\n",
    "\n",
    "print(\"Train rows:\", len(train_df), \"Valid rows:\", len(valid_df))\n",
    "print(\"Features used:\", len(feature_cols))\n",
    "\n",
    "# Identify categorical features (keep similar to LGBM coded columns)\n",
    "potential_cat = {\n",
    "    'window_type_code','club_member_status','fashion_news_frequency','postal_code',\n",
    "    'product_type_no','product_group_name','index_code','section_no',\n",
    "    'graphical_appearance_no','colour_group_code','perceived_colour_value_id',\n",
    "    'perceived_colour_master_id','index_group_no','garment_group_no'\n",
    "}\n",
    "cat_features = [i for i, c in enumerate(feature_cols) if c in potential_cat]\n",
    "\n",
    "print(\"Categorical feature count:\", len(cat_features))\n",
    "\n",
    "# ~ 24gb of ram usage, 21s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1ce40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with any history: 1356709\n",
      "Users with 0 history but some recent: 0\n",
      "Users with history but no recent activity: 1121432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 – user activity stats (train + valid union)\n",
    "tmp = pd.concat(\n",
    "    [\n",
    "        train_df[['customer_id','cust_purchases_4w','customer_total_purchases']],\n",
    "        valid_df[['customer_id','cust_purchases_4w','customer_total_purchases']],\n",
    "    ],\n",
    "    ignore_index=True\n",
    ").drop_duplicates('customer_id')\n",
    "\n",
    "print(\"Users with any history:\", (tmp['customer_total_purchases'] > 0).sum())\n",
    "print(\"Users with 0 history but some recent:\",\n",
    "      ((tmp['customer_total_purchases'] == 0) & (tmp['cust_purchases_4w'] > 0)).sum())\n",
    "print(\"Users with history but no recent activity:\",\n",
    "      ((tmp['customer_total_purchases'] > 0) & (tmp['cust_purchases_4w'] == 0)).sum())\n",
    "del tmp\n",
    "gc.collect()\n",
    "\n",
    "# ~ 16gb of ram usage, 4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d39c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train group size (by customer_id): 616\n",
      "Max valid group size (by customer_id): 593\n",
      "Saved CatBoost ranker inputs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4 – memory-lean capped ranking frame for GPU (≤1023 per group), vectorized\n",
    "MAX_GROUP = 1023  # GPU hard limit\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def build_keep_mask(df, max_group):\n",
    "    # Work on a tiny meta frame only\n",
    "    meta = df[['customer_id', 'label']].copy()\n",
    "    meta['_row'] = np.arange(len(meta), dtype=np.int64)\n",
    "    meta['label'] = meta['label'].astype('int8')\n",
    "\n",
    "    # Keep all positives and compute per-group negative budget\n",
    "    pos_mask = meta['label'] == 1\n",
    "    pos_cnt = meta.loc[pos_mask].groupby('customer_id')['label'].size()\n",
    "    neg_budget_per_group = (max_group - pos_cnt).clip(lower=0)\n",
    "    # groups with no positives get full budget\n",
    "    neg_budget_per_group = neg_budget_per_group.astype('int32')\n",
    "\n",
    "    # For negatives, assign random order within each group and take up to budget\n",
    "    neg_meta = meta.loc[~pos_mask, ['customer_id', '_row']].copy()\n",
    "    neg_meta['_r'] = rng.integers(0, np.iinfo(np.uint32).max, size=len(neg_meta), dtype=np.uint32)\n",
    "    neg_meta = neg_meta.sort_values(['customer_id', '_r'], kind='mergesort')\n",
    "    neg_meta['_rk'] = neg_meta.groupby('customer_id').cumcount().astype('int32')\n",
    "    neg_meta['_budget'] = neg_meta['customer_id'].map(neg_budget_per_group).fillna(max_group).astype('int32')\n",
    "\n",
    "    keep_neg_rows = neg_meta.loc[neg_meta['_rk'] < neg_meta['_budget'], '_row'].to_numpy()\n",
    "    keep_pos_rows = meta.loc[pos_mask, '_row'].to_numpy()\n",
    "    keep_rows = np.concatenate([keep_pos_rows, keep_neg_rows])\n",
    "\n",
    "    mask = np.zeros(len(df), dtype=bool)\n",
    "    mask[keep_rows] = True\n",
    "    return mask\n",
    "\n",
    "# Build masks without duplicating feature columns\n",
    "train_keep = build_keep_mask(train_df, MAX_GROUP)\n",
    "valid_keep = build_keep_mask(valid_df, MAX_GROUP)\n",
    "\n",
    "# Filter once; then sort and densify groups\n",
    "train_df = train_df.loc[train_keep].reset_index(drop=True)\n",
    "valid_df = valid_df.loc[valid_keep].reset_index(drop=True)\n",
    "\n",
    "train_df = train_df.sort_values('customer_id', kind='mergesort')\n",
    "valid_df = valid_df.sort_values('customer_id', kind='mergesort')\n",
    "\n",
    "# Train: dense ids from its own customers\n",
    "train_cust_ids = train_df['customer_id'].unique()\n",
    "cust_to_group_train = {cid: i for i, cid in enumerate(train_cust_ids)}\n",
    "train_group_id = train_df['customer_id'].map(cust_to_group_train).astype('int32')\n",
    "\n",
    "# Valid: independent dense ids from its own customers\n",
    "valid_cust_ids = valid_df['customer_id'].unique()\n",
    "cust_to_group_valid = {cid: i for i, cid in enumerate(valid_cust_ids)}\n",
    "valid_group_id = valid_df['customer_id'].map(cust_to_group_valid).astype('int32')\n",
    "\n",
    "# Sanity: max group size <= 1023 (by customer_id)\n",
    "max_train_group = train_df.groupby('customer_id').size().max()\n",
    "max_valid_group = valid_df.groupby('customer_id').size().max()\n",
    "print(\"Max train group size (by customer_id):\", max_train_group)\n",
    "print(\"Max valid group size (by customer_id):\", max_valid_group)\n",
    "assert max_train_group <= 1023, \"GPU requires ≤1023 per group\"\n",
    "assert max_valid_group <= 1023, \"GPU requires ≤1023 per group\"\n",
    "\n",
    "# Downcast numerics BEFORE Pool creation to avoid big temporary buffers\n",
    "for c in feature_cols:\n",
    "    if pd.api.types.is_float_dtype(train_df[c]):\n",
    "        train_df[c] = train_df[c].astype('float32')\n",
    "        valid_df[c] = valid_df[c].astype('float32')\n",
    "\n",
    "# Keep only genuinely low-card categorical features to avoid heavy CTR tables\n",
    "low_card_keep = {'window_type_code','club_member_status','fashion_news_frequency'}\n",
    "cat_features_restricted = [i for i, c in enumerate(feature_cols) if c in low_card_keep]\n",
    "\n",
    "# === NEW: save pre-built ranking data for reuse ===\n",
    "np.save(\"../data/outputs/cb_train_group_id.npy\", train_group_id.to_numpy())\n",
    "np.save(\"../data/outputs/cb_valid_group_id.npy\", valid_group_id.to_numpy())\n",
    "\n",
    "# Save features + labels as parquet (already filtered & downcasted)\n",
    "train_df.to_parquet(\"../data/outputs/cb_train_frame.parquet\", index=False)\n",
    "valid_df.to_parquet(\"../data/outputs/cb_valid_frame.parquet\", index=False)\n",
    "\n",
    "# Save catboost-specific meta (feature_cols and restricted cat features)\n",
    "cb_meta = {\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"cat_features_restricted\": cat_features_restricted,\n",
    "}\n",
    "with open(\"../data/outputs/cb_ranker_meta.json\", \"w\") as f:\n",
    "    json.dump(cb_meta, f)\n",
    "\n",
    "print(\"Saved CatBoost ranker inputs.\")\n",
    "\n",
    "# Free DataFrames; Pools hold their own memory\n",
    "del train_df, valid_df, train_keep, valid_keep, train_group_id, valid_group_id\n",
    "del cust_to_group_train, cust_to_group_valid\n",
    "gc.collect()\n",
    "\n",
    "# ~ 34gb of ram usage, 6 min 6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3b7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded prebuilt pools.\n",
      "Pool train rows: 128475160\n",
      "Pool valid rows: 32048094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1062"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### NEED TO RUN CELL 5 AND 6 TO TRAIN THE MODEL WHEN NO CHANGES TO CANDIDATES OR FEATURES\n",
    "\n",
    "# Cell 5\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import Pool\n",
    "\n",
    "with open(\"../data/outputs/cb_ranker_meta.json\") as f:\n",
    "    cb_meta = json.load(f)\n",
    "\n",
    "feature_cols = cb_meta[\"feature_cols\"]\n",
    "cat_features_restricted = cb_meta[\"cat_features_restricted\"]\n",
    "\n",
    "train_df = pd.read_parquet(\"../data/outputs/cb_train_frame.parquet\")\n",
    "valid_df = pd.read_parquet(\"../data/outputs/cb_valid_frame.parquet\")\n",
    "\n",
    "train_group_id = np.load(\"../data/outputs/cb_train_group_id.npy\")\n",
    "valid_group_id = np.load(\"../data/outputs/cb_valid_group_id.npy\")\n",
    "\n",
    "pool_train = Pool(\n",
    "    data=train_df[feature_cols],\n",
    "    label=train_df[\"label\"].astype(\"int8\").to_numpy(),\n",
    "    group_id=train_group_id,\n",
    "    cat_features=cat_features_restricted,\n",
    ")\n",
    "pool_valid = Pool(\n",
    "    data=valid_df[feature_cols],\n",
    "    label=valid_df[\"label\"].astype(\"int8\").to_numpy(),\n",
    "    group_id=valid_group_id,\n",
    "    cat_features=cat_features_restricted,\n",
    ")\n",
    "\n",
    "print(\"Loaded prebuilt pools.\")\n",
    "print(\"Pool train rows:\", pool_train.shape[0])\n",
    "print(\"Pool valid rows:\", pool_valid.shape[0])\n",
    "\n",
    "del train_df, valid_df\n",
    "gc.collect()\n",
    "\n",
    "# ~ xgb of ram usage, 2 min 15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71846857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric PFound is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric NDCG:top=12;type=Base is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9861038\tbest: 0.9861038 (0)\ttotal: 2.1s\tremaining: 17m 28s\n",
      "10:\ttest: 0.9868903\tbest: 0.9868903 (10)\ttotal: 15.7s\tremaining: 11m 37s\n",
      "20:\ttest: 0.9869727\tbest: 0.9869727 (20)\ttotal: 29.4s\tremaining: 11m 11s\n",
      "30:\ttest: 0.9870390\tbest: 0.9870390 (30)\ttotal: 43.1s\tremaining: 10m 52s\n",
      "40:\ttest: 0.9870637\tbest: 0.9870649 (35)\ttotal: 56.8s\tremaining: 10m 35s\n",
      "50:\ttest: 0.9870768\tbest: 0.9870801 (48)\ttotal: 1m 10s\tremaining: 10m 19s\n",
      "60:\ttest: 0.9871203\tbest: 0.9871203 (60)\ttotal: 1m 23s\tremaining: 10m 3s\n",
      "70:\ttest: 0.9871385\tbest: 0.9871400 (66)\ttotal: 1m 37s\tremaining: 9m 49s\n",
      "80:\ttest: 0.9871366\tbest: 0.9871413 (76)\ttotal: 1m 51s\tremaining: 9m 34s\n",
      "90:\ttest: 0.9871598\tbest: 0.9871641 (88)\ttotal: 2m 4s\tremaining: 9m 20s\n",
      "100:\ttest: 0.9871641\tbest: 0.9871655 (94)\ttotal: 2m 18s\tremaining: 9m 6s\n",
      "110:\ttest: 0.9871655\tbest: 0.9871702 (104)\ttotal: 2m 31s\tremaining: 8m 52s\n",
      "120:\ttest: 0.9871631\tbest: 0.9871702 (104)\ttotal: 2m 45s\tremaining: 8m 38s\n",
      "130:\ttest: 0.9871683\tbest: 0.9871710 (129)\ttotal: 2m 59s\tremaining: 8m 24s\n",
      "140:\ttest: 0.9871722\tbest: 0.9871735 (137)\ttotal: 3m 12s\tremaining: 8m 10s\n",
      "150:\ttest: 0.9871717\tbest: 0.9871735 (137)\ttotal: 3m 26s\tremaining: 7m 56s\n",
      "160:\ttest: 0.9871801\tbest: 0.9871801 (160)\ttotal: 3m 40s\tremaining: 7m 43s\n",
      "170:\ttest: 0.9871814\tbest: 0.9871879 (166)\ttotal: 3m 53s\tremaining: 7m 29s\n",
      "180:\ttest: 0.9871815\tbest: 0.9871879 (166)\ttotal: 4m 7s\tremaining: 7m 15s\n",
      "190:\ttest: 0.9871978\tbest: 0.9871978 (190)\ttotal: 4m 20s\tremaining: 7m 1s\n",
      "200:\ttest: 0.9872052\tbest: 0.9872052 (200)\ttotal: 4m 34s\tremaining: 6m 48s\n",
      "210:\ttest: 0.9872017\tbest: 0.9872059 (202)\ttotal: 4m 48s\tremaining: 6m 34s\n",
      "220:\ttest: 0.9872142\tbest: 0.9872142 (220)\ttotal: 5m 1s\tremaining: 6m 20s\n",
      "230:\ttest: 0.9872135\tbest: 0.9872165 (224)\ttotal: 5m 15s\tremaining: 6m 7s\n",
      "240:\ttest: 0.9872223\tbest: 0.9872223 (240)\ttotal: 5m 28s\tremaining: 5m 53s\n",
      "250:\ttest: 0.9872206\tbest: 0.9872223 (240)\ttotal: 5m 42s\tremaining: 5m 39s\n",
      "260:\ttest: 0.9872282\tbest: 0.9872282 (260)\ttotal: 5m 55s\tremaining: 5m 25s\n",
      "270:\ttest: 0.9872399\tbest: 0.9872399 (270)\ttotal: 6m 9s\tremaining: 5m 12s\n",
      "280:\ttest: 0.9872330\tbest: 0.9872399 (270)\ttotal: 6m 22s\tremaining: 4m 58s\n",
      "290:\ttest: 0.9872439\tbest: 0.9872439 (289)\ttotal: 6m 36s\tremaining: 4m 44s\n",
      "300:\ttest: 0.9872429\tbest: 0.9872447 (292)\ttotal: 6m 50s\tremaining: 4m 31s\n",
      "310:\ttest: 0.9872370\tbest: 0.9872447 (292)\ttotal: 7m 3s\tremaining: 4m 17s\n",
      "320:\ttest: 0.9872338\tbest: 0.9872447 (292)\ttotal: 7m 17s\tremaining: 4m 3s\n",
      "330:\ttest: 0.9872361\tbest: 0.9872447 (292)\ttotal: 7m 30s\tremaining: 3m 50s\n",
      "340:\ttest: 0.9872441\tbest: 0.9872447 (292)\ttotal: 7m 44s\tremaining: 3m 36s\n",
      "bestTest = 0.9872447022\n",
      "bestIteration = 292\n",
      "Shrink model to first 293 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x7b7737500910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6 – GPU CatBoost ranker\n",
    "\n",
    "model = CatBoostRanker(\n",
    "    loss_function='YetiRank',\n",
    "    eval_metric='NDCG:top=12',\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    iterations=500,\n",
    "    border_count=64,\n",
    "    random_seed=42,\n",
    "    early_stopping_rounds=50,\n",
    "    task_type='GPU',\n",
    "    devices='0',\n",
    "    gpu_ram_part=0.7,\n",
    "    one_hot_max_size=10,\n",
    "    max_ctr_complexity=1,\n",
    "    verbose=10,\n",
    "    metric_period=10,\n",
    ")\n",
    "model.fit(pool_train, eval_set=pool_valid)\n",
    "# ~ 30gb of ram usage, 5 min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3deef352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1154"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del pool_train, pool_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad2b7c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost scored rows: 160523254\n",
      "CatBoost unique customers: 1371980\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 – scoring (single Pool, no group_id; avoid batch Pool overhead)\n",
    "FEATURE_PATH = '../data/outputs/features.parquet'\n",
    "data_full = pd.read_parquet(FEATURE_PATH, columns=feature_cols + ['customer_id','article_id'])\n",
    "\n",
    "# Downcast scoring frame to float32 (safety)\n",
    "for c in feature_cols:\n",
    "    if pd.api.types.is_float_dtype(data_full[c]):\n",
    "        data_full[c] = data_full[c].astype('float32')\n",
    "\n",
    "infer_pool = Pool(\n",
    "    data=data_full[feature_cols],\n",
    "    cat_features=cat_features_restricted\n",
    ")\n",
    "\n",
    "scores = model.predict(infer_pool).astype(np.float32)\n",
    "\n",
    "all_data_rank_cb = data_full[['customer_id','article_id']].copy()\n",
    "all_data_rank_cb['score'] = scores\n",
    "\n",
    "del infer_pool, data_full, scores\n",
    "gc.collect()\n",
    "\n",
    "print(\"CatBoost scored rows:\", len(all_data_rank_cb))\n",
    "print(\"CatBoost unique customers:\", all_data_rank_cb['customer_id'].nunique())\n",
    "\n",
    "# ~ 39gb of ram usage, 2 min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b46ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_df_rank_cb_int rows: 1371980\n",
      "pred_df_rank_cb_int customers: 1371980\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 – build top-12 predictions per customer\n",
    "all_data_rank_cb['article_id_str'] = '0' + all_data_rank_cb['article_id'].astype(str)\n",
    "\n",
    "BATCH_CUSTOMERS = 500_000\n",
    "unique_cust = all_data_rank_cb['customer_id'].unique()\n",
    "pred_parts = []\n",
    "\n",
    "for start in range(0, len(unique_cust), BATCH_CUSTOMERS):\n",
    "    end = min(start + BATCH_CUSTOMERS, len(unique_cust))\n",
    "    cust_chunk = unique_cust[start:end]\n",
    "    chunk = all_data_rank_cb[all_data_rank_cb['customer_id'].isin(cust_chunk)].copy()\n",
    "    chunk = chunk.sort_values(['customer_id','score'], ascending=[True, False])\n",
    "    chunk = chunk.groupby('customer_id', group_keys=False).head(12)\n",
    "    part = (\n",
    "        chunk.groupby('customer_id')['article_id_str']\n",
    "             .apply(lambda x: ' '.join(x))\n",
    "             .reset_index()\n",
    "             .rename(columns={'customer_id':'customer_id_int','article_id_str':'prediction'})\n",
    "    )\n",
    "    pred_parts.append(part)\n",
    "    del chunk, part\n",
    "    gc.collect()\n",
    "\n",
    "pred_df_rank_cb_int = pd.concat(pred_parts, ignore_index=True)\n",
    "del pred_parts\n",
    "gc.collect()\n",
    "\n",
    "print(\"pred_df_rank_cb_int rows:\", len(pred_df_rank_cb_int))\n",
    "print(\"pred_df_rank_cb_int customers:\", pred_df_rank_cb_int['customer_id_int'].nunique())\n",
    "\n",
    "# ~ 26gb of ram usage, 3 min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58b93f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission customers: 1371980\n",
      "pred_df_rank_cb_int customers: 1371980\n",
      "rows in sub after merge: 1371980\n",
      "rows with model preds (raw): 1371980\n",
      "rows needing fallback (raw): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_id_int</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>6883939031699146327</td>\n",
       "      <td>0568601043 0568601006 0751471001 0751471043 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>-7200416642310594310</td>\n",
       "      <td>0918292001 0866731001 0751471001 0706016001 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>-6846340800584936</td>\n",
       "      <td>0794321007 0916468003 0918292001 0852643003 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>-94071612138601410</td>\n",
       "      <td>0751471001 0751471043 0915529003 0863595006 05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>-283965518499174310</td>\n",
       "      <td>0730683050 0818320001 0896152002 0927530004 07...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id      customer_id_int  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...  6883939031699146327   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e... -7200416642310594310   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...    -6846340800584936   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   -94071612138601410   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...  -283965518499174310   \n",
       "\n",
       "                                          prediction  \n",
       "0  0568601043 0568601006 0751471001 0751471043 09...  \n",
       "1  0918292001 0866731001 0751471001 0706016001 09...  \n",
       "2  0794321007 0916468003 0918292001 0852643003 09...  \n",
       "3  0751471001 0751471043 0915529003 0863595006 05...  \n",
       "4  0730683050 0818320001 0896152002 0927530004 07...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9\n",
    "sub = pd.read_csv(\n",
    "    '../data/input_data/sample_submission.csv',\n",
    "    usecols=['customer_id'],\n",
    "    dtype={'customer_id':'string'}\n",
    ")\n",
    "sub['customer_id_int'] = sub['customer_id'].str[-16:].apply(lambda h: np.int64(np.uint64(int(h,16))))\n",
    "\n",
    "print(\"sample_submission customers:\", sub['customer_id_int'].nunique())\n",
    "print(\"pred_df_rank_cb_int customers:\", pred_df_rank_cb_int['customer_id_int'].nunique())\n",
    "\n",
    "sub = sub.merge(pred_df_rank_cb_int, how='left', on='customer_id_int')\n",
    "print(\"rows in sub after merge:\", len(sub))\n",
    "print(\"rows with model preds (raw):\", sub['prediction'].notna().sum())\n",
    "print(\"rows needing fallback (raw):\", sub['prediction'].isna().sum())\n",
    "\n",
    "gp = pd.read_json('../data/outputs/general_pred_str.json', typ='series')\n",
    "general_pred_str = gp['general_pred_str']\n",
    "sub['prediction'] = sub['prediction'].fillna(general_pred_str)\n",
    "fallback_items = general_pred_str.split()\n",
    "\n",
    "def pad_to_12(pred):\n",
    "    items = pred.split()\n",
    "    if len(items) >= 12:\n",
    "        return ' '.join(items[:12])\n",
    "    seen = set(items)\n",
    "    for art in fallback_items:\n",
    "        if art not in seen:\n",
    "            items.append(art)\n",
    "            seen.add(art)\n",
    "        if len(items) == 12:\n",
    "            break\n",
    "    return ' '.join(items)\n",
    "\n",
    "sub['prediction'] = sub['prediction'].apply(pad_to_12)\n",
    "\n",
    "sub[['customer_id','prediction']].to_csv(\n",
    "    '../data/submission/catboost_ranker_submission.csv',\n",
    "    index=False\n",
    ")\n",
    "sub.head()\n",
    "\n",
    "# ~ 20gb of ram usage, 17s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "112ad185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value                     21.5910\n",
      "article_mean_price        15.0095\n",
      "days_since_last_purchase  10.6474\n",
      "window_type_code          10.5916\n",
      "garment_group_no          8.0362\n",
      "section_no                7.7722\n",
      "article_total_purchases   7.5244\n",
      "product_group_name        5.6467\n",
      "product_type_no           4.0439\n",
      "cust_purchases_1w         3.2199\n",
      "colour_group_code         1.8614\n",
      "article_unique_customers  1.3066\n",
      "customer_mean_price       0.5308\n",
      "perceived_colour_master_id 0.4590\n",
      "graphical_appearance_no   0.3980\n",
      "perceived_colour_value_id 0.3520\n",
      "index_code                0.2951\n",
      "cust_purchases_4w         0.2696\n",
      "customer_days_since_last_purchase 0.2052\n",
      "age                       0.1148\n",
      "customer_unique_articles  0.0979\n",
      "index_group_no            0.0240\n",
      "customer_total_purchases  0.0028\n",
      "club_member_status        0.0000\n",
      "fashion_news_frequency    0.0000\n",
      "postal_code               0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 10 – feature importance (CatBoost)\n",
    "from catboost import EFstrType\n",
    "\n",
    "# Use PredictionValuesChange, which does NOT require passing data\n",
    "importances = model.get_feature_importance(type=EFstrType.PredictionValuesChange)\n",
    "\n",
    "for name, imp in sorted(zip(feature_cols, importances), key=lambda x: -x[1]):\n",
    "    print(f\"{name:25s} {imp:.4f}\")\n",
    "\n",
    "# Clean up big objects (all_data_rank_cb etc. are already gone by here)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bee896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
