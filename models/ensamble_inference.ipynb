{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbf457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/ICTProject/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:18: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from optuna import progress_bar as pbar_module\n",
      "/home/coder/ICTProject/.venv/lib/python3.11/site-packages/distributed/diagnostics/rmm.py:8: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n",
      "  import rmm\n",
      "/home/coder/ICTProject/.venv/lib/python3.11/site-packages/rmm/__init__.py:15: FutureWarning: The cuda.cuda module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.driver module instead.\n",
      "  from rmm import mr\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRanker, Pool\n",
    "\n",
    "FEATURES_PATH = \"../data/outputs/features_week=20200922.parquet\"\n",
    "CAT_MODEL_PATH = \"../data/outputs/catboost_ranker.model\"\n",
    "LGB_MODEL_PATH = \"../data/outputs/lgbm_ranker.model\"\n",
    "XGB_MODEL_PATH = \"../data/outputs/xgb_ranker.model\"\n",
    "SAMPLE_PATH = \"../data/input_data/sample_submission.csv\"\n",
    "GENERAL_PATH = \"../data/outputs/general_pred_str.json\"\n",
    "OUT_PATH = \"../data/submission/ensemble_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e205330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing parquet reader...\n",
      "Total rows: 250982495\n",
      "Num feature columns: 34\n",
      "Loading CatBoost...\n",
      "Loading LightGBM...\n",
      "Loading XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171684/341085214.py:29: UserWarning: [08:23:28] WARNING: /workspace/src/c_api/c_api.cc:1511: Unknown file format: `model`. Using UBJSON (`ubj`) as a guess.\n",
      "  xgb_model.load_model(XGB_MODEL_PATH)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Preparing parquet reader...\")\n",
    "\n",
    "with open(\"../data/outputs/dataset_meta.json\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "feature_cols = meta[\"model_features\"]\n",
    "\n",
    "pf = pq.ParquetFile(FEATURES_PATH)\n",
    "num_rows = pf.metadata.num_rows\n",
    "\n",
    "print(\"Total rows:\", num_rows)\n",
    "print(\"Num feature columns:\", len(feature_cols))\n",
    "\n",
    "print(\"Loading CatBoost...\")\n",
    "cat_model = CatBoostRanker()\n",
    "cat_model.load_model(CAT_MODEL_PATH)\n",
    "\n",
    "print(\"Loading LightGBM...\")\n",
    "lgb_model = lgb.Booster(model_file=LGB_MODEL_PATH)\n",
    "\n",
    "print(\"Loading XGBoost...\")\n",
    "xgb_model = xgb.Booster()\n",
    "xgb_model.load_model(XGB_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Row-groups: 100%|██████████| 240/240 [1:42:29<00:00, 25.62s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "\n",
    "print(\"Running batch predictions...\")\n",
    "\n",
    "BATCH = 20_000_000 ## Batch dependent on memory capacity\n",
    "scores_cat = np.memmap(\"tmp_cat.bin\", dtype=\"float32\", mode=\"w+\", shape=(num_rows,))\n",
    "scores_lgb = np.memmap(\"tmp_lgb.bin\", dtype=\"float32\", mode=\"w+\", shape=(num_rows,))\n",
    "scores_xgb = np.memmap(\"tmp_xgb.bin\", dtype=\"float32\", mode=\"w+\", shape=(num_rows,))\n",
    "\n",
    "row_ptr = 0\n",
    "buffer = []\n",
    "buffer_rows = 0\n",
    "\n",
    "for rg in tqdm(range(pf.num_row_groups), desc=\"Row-groups\"):\n",
    "\n",
    "    # read row group\n",
    "    rg_df = pf.read_row_group(rg).to_pandas()\n",
    "\n",
    "    # enforce features\n",
    "    for col in feature_cols:\n",
    "        if col not in rg_df.columns:\n",
    "            rg_df[col] = 0.0\n",
    "\n",
    "    buffer.append(rg_df)\n",
    "    buffer_rows += len(rg_df)\n",
    "\n",
    "    # process batch if buffer is large enough\n",
    "    if buffer_rows >= BATCH or rg == pf.num_row_groups - 1:\n",
    "\n",
    "        df = pd.concat(buffer, ignore_index=True)\n",
    "        X = df[feature_cols].astype(\"float32\")\n",
    "        n = len(df)\n",
    "\n",
    "        # CatBoost\n",
    "        scores_cat[row_ptr:row_ptr+n] = cat_model.predict(Pool(X)).astype(\"float32\")\n",
    "\n",
    "        # LightGBM\n",
    "        scores_lgb[row_ptr:row_ptr+n] = lgb_model.predict(\n",
    "            X, num_iteration=lgb_model.best_iteration\n",
    "        ).astype(\"float32\")\n",
    "\n",
    "        # XGBoost\n",
    "        dmat = xgb.DMatrix(X)\n",
    "        scores_xgb[row_ptr:row_ptr+n] = xgb_model.predict(\n",
    "            dmat,\n",
    "            iteration_range=(0, xgb_model.best_iteration + 1)\n",
    "        ).astype(\"float32\")\n",
    "\n",
    "        row_ptr += n\n",
    "        buffer = []\n",
    "        buffer_rows = 0\n",
    "\n",
    "        del df, X, dmat\n",
    "        gc.collect()\n",
    "\n",
    "        # 152 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba8906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: 0.5 0.3 0.2\n"
     ]
    }
   ],
   "source": [
    "# weights (if added to 1.0), or validation scores\n",
    "s_xgb = 0.20\n",
    "s_lgb = 0.30\n",
    "s_cat = 0.50\n",
    "\n",
    "# Compute normalized weights scaled to 1.0\n",
    "total = s_xgb + s_lgb + s_cat\n",
    "\n",
    "w_xgb = s_xgb / total\n",
    "w_lgb = s_lgb / total\n",
    "w_cat = s_cat / total\n",
    "\n",
    "print(\"Weights:\", w_cat, w_lgb, w_xgb)\n",
    "\n",
    "# Apply weighted ensemble\n",
    "ensemble_scores = (\n",
    "    w_cat * scores_cat +\n",
    "    w_lgb * scores_lgb +\n",
    "    w_xgb * scores_xgb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee27c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## optional when rerunning with new weights\n",
    "# del pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da24c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171684/234411157.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top12[\"article_id_str\"] = top12[\"article_id\"].astype(str).str.zfill(10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_df ready, rows: 1371980\n",
      "Sample rows: 1371980\n",
      "Matched predictions: 1371980\n",
      "Expected: 1371980\n",
      "Saved ensemble submission: ../data/submission/ensemble_submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_id_int</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>6883939031699146327</td>\n",
       "      <td>0568601043 0568601044 0568601006 0568601007 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>-7200416642310594310</td>\n",
       "      <td>0673677002 0918522001 0448509014 0706016001 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>-6846340800584936</td>\n",
       "      <td>0794321007 0794321011 0794321008 0851400020 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>-94071612138601410</td>\n",
       "      <td>0794321011 0730683050 0804992017 0805000001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>-283965518499174310</td>\n",
       "      <td>0896152002 0730683050 0730683062 0896152001 07...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id      customer_id_int  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...  6883939031699146327   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e... -7200416642310594310   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...    -6846340800584936   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   -94071612138601410   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...  -283965518499174310   \n",
       "\n",
       "                                          prediction  \n",
       "0  0568601043 0568601044 0568601006 0568601007 08...  \n",
       "1  0673677002 0918522001 0448509014 0706016001 09...  \n",
       "2  0794321007 0794321011 0794321008 0851400020 08...  \n",
       "3  0794321011 0730683050 0804992017 0805000001 07...  \n",
       "4  0896152002 0730683050 0730683062 0896152001 07...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Rebuild pred_df if missing\n",
    "if \"pred_df\" not in locals():\n",
    "    import pyarrow.parquet as pq\n",
    "\n",
    "    pf = pq.ParquetFile(FEATURES_PATH)\n",
    "    num_rows = pf.metadata.num_rows\n",
    "    base_df = pf.read(columns=[\"customer_id\", \"article_id\"]).to_pandas()\n",
    "\n",
    "    scores_cat = np.memmap(\"tmp_cat.bin\", dtype=\"float32\", mode=\"r\", shape=(num_rows,))\n",
    "    scores_lgb = np.memmap(\"tmp_lgb.bin\", dtype=\"float32\", mode=\"r\", shape=(num_rows,))\n",
    "    scores_xgb = np.memmap(\"tmp_xgb.bin\", dtype=\"float32\", mode=\"r\", shape=(num_rows,))\n",
    "\n",
    "    ensemble_scores = (w_cat * scores_cat) + (w_lgb * scores_lgb) + (w_xgb * scores_xgb)\n",
    "\n",
    "    base_df[\"score\"] = ensemble_scores\n",
    "    df_sorted = base_df.sort_values([\"customer_id\", \"score\"], ascending=[True, False])\n",
    "    top12 = df_sorted.groupby(\"customer_id\", group_keys=False).head(12)\n",
    "    top12[\"article_id_str\"] = top12[\"article_id\"].astype(str).str.zfill(10)\n",
    "\n",
    "    pred_df = (\n",
    "        top12.groupby(\"customer_id\")[\"article_id_str\"]\n",
    "        .apply(lambda x: \" \".join(x))\n",
    "        .reset_index()\n",
    "        .rename(columns={\"customer_id\": \"customer_id_int\", \"article_id_str\": \"prediction\"})\n",
    "    )\n",
    "\n",
    "def hex16_to_int64(s):\n",
    "    return np.int64(np.uint64(int(s[-16:], 16)))\n",
    "\n",
    "# -------------------------------\n",
    "# Load fallback data\n",
    "# -------------------------------\n",
    "gp = json.load(open(GENERAL_PATH))\n",
    "fallback_str = gp[\"general_pred_str\"]\n",
    "fallback_items = fallback_str.split()\n",
    "\n",
    "if \"article_id_str\" in pred_df.columns and \"prediction\" not in pred_df.columns:\n",
    "    pred_df = pred_df.rename(columns={\"article_id_str\": \"prediction\"})\n",
    "\n",
    "if \"customer_id\" in pred_df.columns and \"customer_id_int\" not in pred_df.columns:\n",
    "    pred_df = pred_df.rename(columns={\"customer_id\": \"customer_id_int\"})\n",
    "\n",
    "pred_df[\"customer_id_int\"] = pred_df[\"customer_id_int\"].astype(\"int64\")\n",
    "\n",
    "print(\"pred_df ready, rows:\", len(pred_df))\n",
    "\n",
    "# -------------------------------\n",
    "# Load sample and convert IDs correctly\n",
    "# -------------------------------\n",
    "sample = pd.read_csv(SAMPLE_PATH)\n",
    "\n",
    "sample[\"customer_id_int\"] = sample[\"customer_id\"].apply(hex16_to_int64)\n",
    "sample = sample.drop(columns=[\"prediction\"], errors=\"ignore\")\n",
    "\n",
    "print(\"Sample rows:\", len(sample))\n",
    "\n",
    "# -------------------------------\n",
    "# Merge\n",
    "# -------------------------------\n",
    "sub = sample.merge(pred_df, how=\"left\", on=\"customer_id_int\")\n",
    "\n",
    "print(\"Matched predictions:\", sub[\"prediction\"].notna().sum())\n",
    "print(\"Expected:\", len(sample))\n",
    "\n",
    "# -------------------------------\n",
    "# Apply fallback + pad\n",
    "# -------------------------------\n",
    "sub[\"prediction\"] = sub[\"prediction\"].fillna(fallback_str)\n",
    "\n",
    "def pad12(pred):\n",
    "    items = pred.split()\n",
    "    if len(items) >= 12:\n",
    "        return \" \".join(items[:12])\n",
    "    used = set(items)\n",
    "    for art in fallback_items:\n",
    "        if art not in used:\n",
    "            items.append(art)\n",
    "            if len(items) == 12:\n",
    "                break\n",
    "    return \" \".join(items)\n",
    "\n",
    "sub[\"prediction\"] = sub[\"prediction\"].apply(pad12)\n",
    "\n",
    "sub[[\"customer_id\",\"prediction\"]].to_csv(OUT_PATH, index=False)\n",
    "print(\"Saved ensemble submission:\", OUT_PATH)\n",
    "sub.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
