{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5758312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 – imports\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6baafddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 160523254 Valid rows: 160523254\n",
      "Features used: 26\n",
      "Groups train: 1371980 valid: 1371980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2 – load prepared ranking data (same structure as LGBM)\n",
    "META_PATH = '../data/outputs/dataset_meta.json'\n",
    "TRAIN_RANK_PATH = '../data/outputs/train_rank.parquet'\n",
    "VALID_RANK_PATH = '../data/outputs/valid_rank.parquet'\n",
    "GROUP_TRAIN_PATH = '../data/outputs/groups_train.npy'\n",
    "GROUP_VALID_PATH = '../data/outputs/groups_valid.npy'\n",
    "\n",
    "with open(META_PATH) as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "# Use intersected feature list written by prepare_model_dataset\n",
    "feature_cols = meta['model_features']\n",
    "\n",
    "train_df = pd.read_parquet(TRAIN_RANK_PATH)\n",
    "valid_df = pd.read_parquet(VALID_RANK_PATH)\n",
    "\n",
    "# Safety: enforce intersection (avoids KeyError if meta stale)\n",
    "available = set(train_df.columns)\n",
    "feature_cols = [c for c in feature_cols if c in available]\n",
    "\n",
    "train_group = np.load(GROUP_TRAIN_PATH)\n",
    "valid_group = np.load(GROUP_VALID_PATH)\n",
    "\n",
    "print(\"Train rows:\", len(train_df), \"Valid rows:\", len(valid_df))\n",
    "print(\"Features used:\", len(feature_cols))\n",
    "print(\"Groups train:\", len(train_group), \"valid:\", len(valid_group))\n",
    "\n",
    "# Downcast to float32 where appropriate for XGBoost\n",
    "for c in feature_cols:\n",
    "    if pd.api.types.is_float_dtype(train_df[c]):\n",
    "        train_df[c] = train_df[c].astype('float32')\n",
    "        valid_df[c] = valid_df[c].astype('float32')\n",
    "\n",
    "train_df['label'] = train_df['label'].astype('float32')\n",
    "valid_df['label'] = valid_df['label'].astype('float32')\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# ~ 20gb of ram usage, 17s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef0b9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with any history: 1356709\n",
      "Users with 0 history but some recent: 0\n",
      "Users with history but no recent activity: 1121432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 – user activity stats (same as other rankers)\n",
    "tmp = pd.concat(\n",
    "    [\n",
    "        train_df[['customer_id', 'cust_purchases_4w', 'customer_total_purchases']],\n",
    "        valid_df[['customer_id', 'cust_purchases_4w', 'customer_total_purchases']],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ").drop_duplicates('customer_id')\n",
    "\n",
    "print(\"Users with any history:\", (tmp['customer_total_purchases'] > 0).sum())\n",
    "print(\n",
    "    \"Users with 0 history but some recent:\",\n",
    "    ((tmp['customer_total_purchases'] == 0) & (tmp['cust_purchases_4w'] > 0)).sum(),\n",
    ")\n",
    "print(\n",
    "    \"Users with history but no recent activity:\",\n",
    "    ((tmp['customer_total_purchases'] > 0) & (tmp['cust_purchases_4w'] == 0)).sum(),\n",
    ")\n",
    "del tmp\n",
    "gc.collect()\n",
    "\n",
    "# ~ 20gb of ram usage, 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 – train XGBoost ranker (rank:ndcg)\n",
    "# Prepare DMatrix objects with group arrays\n",
    "dtrain = xgb.DMatrix(\n",
    "    data=train_df[feature_cols],\n",
    "    label=train_df['label'],\n",
    ")\n",
    "dvalid = xgb.DMatrix(\n",
    "    data=valid_df[feature_cols],\n",
    "    label=valid_df['label'],\n",
    ")\n",
    "\n",
    "# XGBoost expects group sizes, not group ids\n",
    "dtrain.set_group(train_group)\n",
    "dvalid.set_group(valid_group)\n",
    "\n",
    "# Basic ranking hyperparameters – comparable to LGBM / CatBoost\n",
    "params = {\n",
    "    'objective': 'rank:ndcg',\n",
    "    'eval_metric': 'ndcg@12',\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'tree_method': 'hist',   # change to 'gpu_hist' if GPU available\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "num_boost_round = 20\n",
    "early_stopping_rounds = 5\n",
    "\n",
    "evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "evals_result = {}\n",
    "\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    evals_result=evals_result,\n",
    "    verbose_eval=1,\n",
    ")\n",
    "\n",
    "print(\"Best iteration:\", bst.best_iteration)\n",
    "print(\"Best valid ndcg@12:\", evals_result['valid']['ndcg@12'][bst.best_iteration])\n",
    "\n",
    "del dtrain, dvalid, train_df, valid_df, train_group, valid_group\n",
    "gc.collect()\n",
    "\n",
    "# ~ 20gb of ram usage, 17s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0409e39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data_rank_xgb rows: 160523254\n",
      "all_data_rank_xgb customers: 1371980\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 – scoring on full feature set (same as LGBM flow)\n",
    "FEATURE_PATH = '../data/outputs/features.parquet'\n",
    "\n",
    "# Load only necessary columns: features + ids\n",
    "data = pd.read_parquet(FEATURE_PATH, columns=feature_cols + ['customer_id', 'article_id'])\n",
    "\n",
    "# Ensure float32 for XGBoost\n",
    "for c in feature_cols:\n",
    "    if pd.api.types.is_float_dtype(data[c]):\n",
    "        data[c] = data[c].astype('float32')\n",
    "\n",
    "BATCH_SIZE = 5_000_000\n",
    "n_rows = len(data)\n",
    "scores = np.empty(n_rows, dtype=np.float32)\n",
    "\n",
    "for start in range(0, n_rows, BATCH_SIZE):\n",
    "    end = min(start + BATCH_SIZE, n_rows)\n",
    "    X_batch = data.iloc[start:end][feature_cols]  # keep as DataFrame with column names\n",
    "    dmatrix_batch = xgb.DMatrix(X_batch)\n",
    "    scores[start:end] = bst.predict(\n",
    "        dmatrix_batch,\n",
    "        iteration_range=(0, bst.best_iteration + 1),\n",
    "    ).astype(np.float32)\n",
    "    del X_batch, dmatrix_batch\n",
    "    gc.collect()\n",
    "\n",
    "all_data_rank_xgb = data[['customer_id', 'article_id']].copy()\n",
    "all_data_rank_xgb['score'] = scores\n",
    "\n",
    "del scores, data\n",
    "gc.collect()\n",
    "\n",
    "print(\"all_data_rank_xgb rows:\", len(all_data_rank_xgb))\n",
    "print(\"all_data_rank_xgb customers:\", all_data_rank_xgb['customer_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68974f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_df_rank_xgb_int rows: 1371980\n",
      "pred_df_rank_xgb_int customers: 1371980\n",
      "Mean items per predicted customer: 12.0\n",
      "Min items per predicted customer: 12\n",
      "Max items per predicted customer: 12\n",
      "Total customer–item pairs: 16463760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6 – build predictions per integer customer_id (top-12)\n",
    "all_data_rank_xgb['article_id_str'] = '0' + all_data_rank_xgb['article_id'].astype(str)\n",
    "\n",
    "BATCH_CUSTOMERS = 500_000\n",
    "unique_cust = all_data_rank_xgb['customer_id'].unique()\n",
    "pred_parts = []\n",
    "\n",
    "for start in range(0, len(unique_cust), BATCH_CUSTOMERS):\n",
    "    end = min(start + BATCH_CUSTOMERS, len(unique_cust))\n",
    "    cust_chunk = unique_cust[start:end]\n",
    "    chunk = all_data_rank_xgb[all_data_rank_xgb['customer_id'].isin(cust_chunk)].copy()\n",
    "    chunk = chunk.sort_values(['customer_id', 'score'], ascending=[True, False])\n",
    "    chunk = chunk.groupby('customer_id', group_keys=False).head(12)\n",
    "    part = (\n",
    "        chunk.groupby('customer_id')['article_id_str']\n",
    "             .apply(lambda x: ' '.join(x))\n",
    "             .reset_index()\n",
    "             .rename(columns={'customer_id': 'customer_id_int',\n",
    "                              'article_id_str': 'prediction'})\n",
    "    )\n",
    "    pred_parts.append(part)\n",
    "    del chunk, part\n",
    "    gc.collect()\n",
    "\n",
    "pred_df_rank_xgb_int = pd.concat(pred_parts, ignore_index=True)\n",
    "del pred_parts\n",
    "gc.collect()\n",
    "\n",
    "print(\"pred_df_rank_xgb_int rows:\", len(pred_df_rank_xgb_int))\n",
    "print(\"pred_df_rank_xgb_int customers:\", pred_df_rank_xgb_int['customer_id_int'].nunique())\n",
    "\n",
    "pred_df_rank_xgb_int['n_items'] = pred_df_rank_xgb_int['prediction'].str.split().str.len()\n",
    "print(\"Mean items per predicted customer:\", pred_df_rank_xgb_int['n_items'].mean())\n",
    "print(\"Min items per predicted customer:\", pred_df_rank_xgb_int['n_items'].min())\n",
    "print(\"Max items per predicted customer:\", pred_df_rank_xgb_int['n_items'].max())\n",
    "print(\"Total customer–item pairs:\", pred_df_rank_xgb_int['n_items'].sum())\n",
    "\n",
    "del all_data_rank_xgb\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e66f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission customers: 1371980\n",
      "pred_df_rank_xgb_int customers: 1371980\n",
      "rows in sub after merge: 1371980\n",
      "rows with model preds (raw): 1371980\n",
      "rows needing fallback (raw): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_id_int</th>\n",
       "      <th>prediction</th>\n",
       "      <th>n_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>6883939031699146327</td>\n",
       "      <td>0568601043 0568601006 0751471043 0915529003 07...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>-7200416642310594310</td>\n",
       "      <td>0909370001 0866731001 0918292001 0827968001 07...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>-6846340800584936</td>\n",
       "      <td>0794321007 0915526001 0916468003 0852643003 09...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>-94071612138601410</td>\n",
       "      <td>0751471043 0915529003 0863595006 0762846006 09...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>-283965518499174310</td>\n",
       "      <td>0896152002 0730683050 0818320001 0791587015 09...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id      customer_id_int  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...  6883939031699146327   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e... -7200416642310594310   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...    -6846340800584936   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   -94071612138601410   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...  -283965518499174310   \n",
       "\n",
       "                                          prediction  n_items  \n",
       "0  0568601043 0568601006 0751471043 0915529003 07...       12  \n",
       "1  0909370001 0866731001 0918292001 0827968001 07...       12  \n",
       "2  0794321007 0915526001 0916468003 0852643003 09...       12  \n",
       "3  0751471043 0915529003 0863595006 0762846006 09...       12  \n",
       "4  0896152002 0730683050 0818320001 0791587015 09...       12  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7 – attach hex ids and merge into sample_submission\n",
    "sub = pd.read_csv(\n",
    "    '../data/input_data/sample_submission.csv',\n",
    "    usecols=['customer_id'],\n",
    "    dtype={'customer_id': 'string'}\n",
    ")\n",
    "sub['customer_id_int'] = sub['customer_id'].str[-16:].apply(\n",
    "    lambda h: np.int64(np.uint64(int(h, 16)))\n",
    ")\n",
    "\n",
    "print(\"sample_submission customers:\", sub['customer_id_int'].nunique())\n",
    "print(\"pred_df_rank_xgb_int customers:\", pred_df_rank_xgb_int['customer_id_int'].nunique())\n",
    "\n",
    "sub = sub.merge(\n",
    "    pred_df_rank_xgb_int,\n",
    "    how='left',\n",
    "    on='customer_id_int'\n",
    ")\n",
    "\n",
    "print(\"rows in sub after merge:\", len(sub))\n",
    "print(\"rows with model preds (raw):\", sub['prediction'].notna().sum())\n",
    "print(\"rows needing fallback (raw):\", sub['prediction'].isna().sum())\n",
    "\n",
    "gp = pd.read_json('../data/outputs/general_pred_str.json', typ='series')\n",
    "general_pred_str = gp['general_pred_str']\n",
    "\n",
    "sub['prediction'] = sub['prediction'].fillna(general_pred_str)\n",
    "fallback_items = general_pred_str.split()\n",
    "\n",
    "def pad_to_12(pred):\n",
    "    items = pred.split()\n",
    "    if len(items) >= 12:\n",
    "        return ' '.join(items[:12])\n",
    "    seen = set(items)\n",
    "    for art in fallback_items:\n",
    "        if art not in seen:\n",
    "            items.append(art)\n",
    "            seen.add(art)\n",
    "        if len(items) == 12:\n",
    "            break\n",
    "    return ' '.join(items)\n",
    "\n",
    "sub['prediction'] = sub['prediction'].apply(pad_to_12)\n",
    "\n",
    "sub[['customer_id', 'prediction']].to_csv(\n",
    "    '../data/submission/xgboost_ranker_submission.csv',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1468ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_type_code          862.9497\n",
      "value                     581.2436\n",
      "cust_purchases_1w         180.4240\n",
      "days_since_last_purchase  117.9940\n",
      "customer_days_since_last_purchase 83.1339\n",
      "article_total_purchases   70.8977\n",
      "product_group_name        62.7714\n",
      "garment_group_no          55.7787\n",
      "index_code                51.6154\n",
      "article_mean_price        49.7249\n",
      "section_no                48.4736\n",
      "customer_mean_price       41.9713\n",
      "graphical_appearance_no   37.9613\n",
      "product_type_no           30.8679\n",
      "article_unique_customers  29.5927\n",
      "customer_unique_articles  26.7493\n",
      "age                       23.1414\n",
      "cust_purchases_4w         22.5028\n",
      "customer_total_purchases  22.1936\n",
      "perceived_colour_master_id 21.6410\n",
      "colour_group_code         20.8729\n",
      "fashion_news_frequency    18.1958\n",
      "postal_code               11.1414\n",
      "perceived_colour_value_id 4.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8 – feature importance (XGBoost gain)\n",
    "importances = bst.get_score(importance_type='gain')  # dict: feature index -> importance\n",
    "\n",
    "# Map back to feature names (XGBoost uses f0, f1, ...)\n",
    "feat_name_map = {f\"f{i}\": name for i, name in enumerate(feature_cols)}\n",
    "items = []\n",
    "for k, v in importances.items():\n",
    "    name = feat_name_map.get(k, k)\n",
    "    items.append((name, v))\n",
    "\n",
    "for name, imp in sorted(items, key=lambda x: -x[1]):\n",
    "    print(f\"{name:25s} {imp:.4f}\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f1e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
